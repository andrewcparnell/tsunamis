
R version 3.2.3 (2015-12-10) -- "Wooden Christmas-Tree"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-redhat-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> # A JAGS model for a constrained radiocarbon chronology for the tsunami data
> 
> # Clear the workspace if necessary
> rm(list=ls())
> 
> # Set the wd and load in packages
> setwd("~/GitHub/tsunamis")
> library(rjags)
Loading required package: coda
Linked to JAGS 4.0.1
Loaded modules: basemod,bugs
> library(ggplot2)
> library(Bchron)
Loading required package: inline
> 
> ### First sort data
> cal = read.table('intcal13.14c',sep=',')
> colnames(cal) = c('calbp','c14age','errorBP','Delta14C','Sigma_per_mil') 
> 
> # Give data
> x_T12 = c(2822,2725) # T12 is first two dates - theta[1]
> sig_T12 = c(20,20) 
> x_T11 = c(2965,3065,3093,3210,3217) # T11 is 5 dates - theta[2]
> sig_T11 = c(20,20,21,21,21)
> x_T10 = c(3085,3069) # T10 has 2 dates - theta[3]
> sig_T10 = c(21,20)
> x_T9 = c(3078) # - theta[4]
> sig_T9 = c(21)
> x_T8 = c(3077) # - theta[5]
> sig_T8 = c(20)
> x_T7_max = c(3540) # max for theta[6]
> sig_T7_max = c(30)
> x_T6_min = c(4742)# - theta[7]
> sig_T6_min = c(23)
> # No dates for T5 - theta[8]
> # No dates for T4 - theta[9]
> x_T4_min_max = c(5090) # This is between T3 and T4 and corresponds to theta[10]
> sig_T4_min_max = c(40)
> # No dates for T3 - theta[11]
> # No dates for T2 - theta[12]
> x_T2_min_max = c(6060) # This is between T1 and T2 and corresponds to theta[13]
> sig_T2_min_max = c(40)
> # No dates for T1 - theta[14]
> x_T1_max_1 = c(6788) # - still theta[14] - max age for T1 - calibrated this is 7585 to 7675
> sig_T1_max_1 = c(26)
> x_T1_max_2 = c(6560) # - still theta[14] - another max age for T1
> sig_T1_max_2 = c(35)
> 
> o = order(cal$calbp) # - JAGS needs the calibration curve to be in order
> data=list(c14=cal$c14age[o],calbp=cal$calbp[o],err=cal$errorBP[o],
+           x_T12=x_T12,x_T11=x_T11,x_T10=x_T10,x_T9=x_T9,x_T8=x_T8,
+           x_T7_max=x_T7_max,x_T6_min=x_T6_min,x_T4_min_max=x_T4_min_max,
+           x_T2_min_max=x_T2_min_max,x_T1_max_1=x_T1_max_1,x_T1_max_2=x_T1_max_2,
+           sig_T12=sig_T12,sig_T11=sig_T11,sig_T10=sig_T10,sig_T9=sig_T9,sig_T8=sig_T8,
+           sig_T7_max=sig_T7_max,sig_T6_min=sig_T6_min,sig_T4_min_max=sig_T4_min_max,
+           sig_T2_min_max=sig_T2_min_max,sig_T1_max_1=sig_T1_max_2,
+           sig_T1_max_2=sig_T1_max_2,n_T12=length(x_T12),n_T11=length(x_T11),
+           n_T10=length(x_T10),n_T9=length(x_T9),n_T8=length(x_T8))
> 
> # To get goo starting values, calibrate some radiocarbon dates and sort them
> # Give some initial values
> source('Initial_values_function_20150624.R')
>   
> # Model definition
> modelstring ='
+ model{
+   # Priors for the ages, make sure they are sorted
+   for(i in 1:14) {
+     # theta[1]=T12,theta[2]=T11,theta[3]=T10,theta[4]=T9,theta[5]=T8,theta[6]=T7,theta[7]=T6,theta[8]=T5,theta[9]=T4,theta[10]=date between T3 and T4,theta[11]=T3,theta[12]=T2,theta[13]=date between 1 and 2,theta[14]=T1
+     theta_raw[i] ~ dunif(0,10000)
+   }
+   theta[1:14] <- sort(theta_raw)
+ 
+   # First do T12 - top of core, youngest - Note this is theta[1]
+   mu_cal_T12 <- interp.lin(theta[1],calbp,c14)
+   sig_cal_T12 <- interp.lin(theta[1],calbp,err)
+   for(i in 1:n_T12) {
+       x_T12[i] ~ dnorm(mu_cal_T12,tau_all_T12[i])
+       tau_all_T12[i] <- 1/sig_sq_all_T12[i]
+       sig_sq_all_T12[i] <- pow(sig_T12[i],2) + pow(sig_cal_T12,2)
+   }
+ 
+   # Now T11 - must be older (bigger) than T12 but younger (smaller) than T10
+   mu_cal_T11 <- interp.lin(theta[2],calbp,c14)
+   sig_cal_T11 <- interp.lin(theta[2],calbp,err)
+   for(i in 1:n_T11) {
+       x_T11[i] ~ dnorm(mu_cal_T11,tau_all_T11[i])
+       tau_all_T11[i] <- 1/sig_sq_all_T11[i]
+       sig_sq_all_T11[i] <- pow(sig_T11[i],2) + pow(sig_cal_T11,2)
+   }
+ 
+   # Now T10 - must be older (bigger) than T11
+   mu_cal_T10 <- interp.lin(theta[3],calbp,c14)
+   sig_cal_T10 <- interp.lin(theta[3],calbp,err)
+   for(i in 1:n_T10) {
+       x_T10[i] ~ dnorm(mu_cal_T10,tau_all_T10[i])
+       tau_all_T10[i] <- 1/sig_sq_all_T10[i]
+       sig_sq_all_T10[i] <- pow(sig_T10[i],2) + pow(sig_cal_T10,2)
+   }
+ 
+   # Now T9
+   mu_cal_T9 <- interp.lin(theta[4],calbp,c14)
+   sig_cal_T9 <- interp.lin(theta[4],calbp,err)
+   for(i in 1:n_T9) {
+       x_T9[i] ~ dnorm(mu_cal_T9,tau_all_T9[i])
+       tau_all_T9[i] <- 1/sig_sq_all_T9[i]
+       sig_sq_all_T9[i] <- pow(sig_T9[i],2) + pow(sig_cal_T9,2)
+   }
+ 
+   # T8
+   mu_cal_T8 <- interp.lin(theta[5],calbp,c14)
+   sig_cal_T8 <- interp.lin(theta[5],calbp,err)
+   for(i in 1:n_T8) {
+       x_T8[i] ~ dnorm(mu_cal_T8,tau_all_T8[i])
+       tau_all_T8[i] <- 1/sig_sq_all_T8[i]
+       sig_sq_all_T8[i] <- pow(sig_T8[i],2) + pow(sig_cal_T8,2)
+   }
+ 
+   # T7 max - dates which are older than theta[6]
+   theta_T7_max <- theta[6] + extra_T7
+   extra_T7 ~ dgamma(4,0.02) # Gamma distribution with mean 200 and sd 100
+   mu_cal_T7_max <- interp.lin(theta_T7_max,calbp,c14)
+   sig_cal_T7_max <- interp.lin(theta_T7_max,calbp,err)
+   x_T7_max ~ dnorm(mu_cal_T7_max,tau_all_T7_max)
+   tau_all_T7_max <- 1/sig_sq_all_T7_max
+   sig_sq_all_T7_max <- pow(sig_T7_max,2) + pow(sig_cal_T7_max,2)
+ 
+   # T6 min - date which is younger than T6
+   theta_T6_min <- theta[7] - extra_T6
+   extra_T6 ~ dgamma(4,0.02) # Gamma distribution with mean 200 and sd 100
+   mu_cal_T6_min <- interp.lin(theta_T6_min,calbp,c14)
+   sig_cal_T6_min <- interp.lin(theta_T6_min,calbp,err)
+   x_T6_min ~ dnorm(mu_cal_T6_min,tau_all_T6_min)
+   tau_all_T6_min <- 1/sig_sq_all_T6_min
+   sig_sq_all_T6_min <- pow(sig_T6_min,2) + pow(sig_cal_T6_min,2)
+ 
+   # No dates at all for T5 - theta[8]
+ 
+   # No dates for T4 - theta[9]
+ 
+   # This is a date which is between T3 and T4
+   mu_cal_T4_min_max <- interp.lin(theta[10],calbp,c14)
+   sig_cal_T4_min_max <- interp.lin(theta[10],calbp,err)
+   x_T4_min_max ~ dnorm(mu_cal_T4_min_max,tau_all_T4_min_max)
+   tau_all_T4_min_max <- 1/sig_sq_all_T4_min_max
+   sig_sq_all_T4_min_max <- pow(sig_T4_min_max,2) + pow(sig_cal_T4_min_max,2)
+ 
+   # No dates for T3 - theta[11]
+   
+   # No dates for T2 - theta[12]
+ 
+   # This is a date between T1 and T2 - theta[13]
+   mu_cal_T2_min_max <- interp.lin(theta[13],calbp,c14)
+   sig_cal_T2_min_max <- interp.lin(theta[13],calbp,err)
+   x_T2_min_max ~ dnorm(mu_cal_T2_min_max,tau_all_T2_min_max)
+   tau_all_T2_min_max <- 1/sig_sq_all_T2_min_max
+   sig_sq_all_T2_min_max <- pow(sig_T2_min_max,2) + pow(sig_cal_T2_min_max,2)
+ 
+   # T1 max - first date which is older than T1
+   theta_T1_max_1 <- theta[14] + extra_T1_1
+   extra_T1_1 ~ dgamma(4,0.02) # Gamma distribution with mean 200 and sd 100
+   mu_cal_T1_max_1 <- interp.lin(theta_T1_max_1,calbp,c14)
+   sig_cal_T1_max_1 <- interp.lin(theta_T1_max_1,calbp,err)
+   x_T1_max_1 ~ dnorm(mu_cal_T1_max_1,tau_all_T1_max_1)
+   tau_all_T1_max_1 <- 1/sig_sq_all_T1_max_1
+   sig_sq_all_T1_max_1 <- pow(sig_T1_max_1,2) + pow(sig_cal_T1_max_1,2)
+ 
+   # T1 max_2 - first date which is older than T1
+   theta_T1_max_2 <- theta[14] + extra_T1_2
+   extra_T1_2 ~ dgamma(4,0.02) # Gamma distribution with mean 200 and sd 100
+   mu_cal_T1_max_2 <- interp.lin(theta_T1_max_2,calbp,c14)
+   sig_cal_T1_max_2 <- interp.lin(theta_T1_max_2,calbp,err)
+   x_T1_max_2 ~ dnorm(mu_cal_T1_max_2,tau_all_T1_max_2)
+   tau_all_T1_max_2 <- 1/sig_sq_all_T1_max_2
+   sig_sq_all_T1_max_2 <- pow(sig_T1_max_2,2) + pow(sig_cal_T1_max_2,2)
+ 
+ }'
> 
> # Run the model in jags
> set.seed(111) # Set the seed for repeatable results
> model=jags.model(textConnection(modelstring), data=data, inits=init,n.chains=4)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 17
   Unobserved stochastic nodes: 18
   Total graph size: 15816

Initializing model

> update(model,n.iter=1e6) # Burnin period
> output=coda.samples(model=model,
+                     variable.names=c("theta",
+                                      "extra_T7",
+                                      "extra_T6",
+                                      "extra_T1_1",
+                                      "extra_T1_2"), 
+                     n.iter=1e6, 
+                     thin=5e2)
> save(output,file='output_20150624.rda')
> #load('output_20150624.rda')
> pdf(file='trace_plot_20150624.pdf',width=8,height=8)
> par(mar=c(2,2,2,2))
> plot(output)
> dev.off()
null device 
          1 
> summary(output)

Iterations = 1001500:2001000
Thinning interval = 500 
Number of chains = 4 
Sample size per chain = 2000 

1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:

             Mean     SD Naive SE Time-series SE
extra_T1_1  281.6  72.44   0.8099         0.8223
extra_T1_2  135.2  62.59   0.6998         0.7061
extra_T6    137.1  62.82   0.7024         2.6422
extra_T7    194.5  90.57   1.0126         1.0234
theta[1]   2867.4  24.42   0.2731         0.2755
theta[2]   3293.8  26.51   0.2964         0.4745
theta[3]   3308.2  23.78   0.2659         0.3976
theta[4]   3324.5  20.78   0.2323         0.2958
theta[5]   3341.4  16.64   0.1861         0.2162
theta[6]   3621.8 102.69   1.1481         1.1860
theta[7]   5579.7  94.55   1.0571         1.9840
theta[8]   5667.7  96.02   1.0736         1.6279
theta[9]   5756.9  84.82   0.9483         1.1075
theta[10]  5845.9  51.69   0.5779         0.6124
theta[11]  6201.6 258.31   2.8880         2.9417
theta[12]  6565.0 259.72   2.9038         3.0125
theta[13]  6923.5  68.10   0.7614         0.7545
theta[14]  7344.3  70.04   0.7831         0.7967

2. Quantiles for each variable:

              2.5%     25%    50%    75%  97.5%
extra_T1_1  153.11  231.45  276.1  325.6  440.3
extra_T1_2   39.80   90.09  125.8  171.7  279.1
extra_T6     39.68   90.75  129.4  175.2  282.2
extra_T7     55.68  126.30  181.5  249.0  404.9
theta[1]   2808.08 2856.79 2865.4 2875.1 2918.8
theta[2]   3268.95 3275.89 3280.2 3327.9 3344.2
theta[3]   3275.73 3288.36 3299.4 3333.3 3350.0
theta[4]   3286.58 3306.10 3328.6 3341.7 3355.6
theta[5]   3300.13 3332.72 3344.0 3353.3 3366.9
theta[6]   3398.15 3556.95 3630.6 3696.2 3798.8
theta[7]   5407.18 5505.55 5585.9 5649.4 5754.7
theta[8]   5469.65 5604.90 5674.3 5735.5 5840.0
theta[9]   5567.89 5705.13 5763.9 5821.3 5890.5
theta[10]  5751.04 5802.71 5856.7 5890.6 5919.9
theta[11]  5825.76 5989.74 6155.4 6376.7 6762.0
theta[12]  6012.97 6384.07 6603.0 6776.7 6945.6
theta[13]  6803.26 6884.57 6920.3 6956.7 7131.8
theta[14]  7187.98 7302.00 7350.4 7392.0 7467.1

> 
> # Congergence diagnostics - all good
> gelman.diag(output)
Potential scale reduction factors:

           Point est. Upper C.I.
extra_T1_1          1          1
extra_T1_2          1          1
extra_T6            1          1
extra_T7            1          1
theta[1]            1          1
theta[2]            1          1
theta[3]            1          1
theta[4]            1          1
theta[5]            1          1
theta[6]            1          1
theta[7]            1          1
theta[8]            1          1
theta[9]            1          1
theta[10]           1          1
theta[11]           1          1
theta[12]           1          1
theta[13]           1          1
theta[14]           1          1

Multivariate psrf

1
> 
> ##########################################################################################
> 
> ## Extract the parameters
> output_2 = do.call(rbind,output)
> 
> # Now create upper and lower CIs
> CIs = t(round(apply(output_2,2,'quantile',c(0.025,0.5,0.975)),0))
> 
> ##########################################################################################
> 
> # First plot - tsunamis on y axis with CIs on x axis
> Tsunami = factor(paste('T',12:1,sep=''),levels=paste('T',1:12,sep=''))
> 
> df_1 = data.frame(Tsunami,CIs=CIs[4+c(1:9,11:12,14),])
> rownames(df_1)=NULL
> colnames(df_1)=c('Tsunami','pc2.5','pc50','pc97.5')
>   
> #ggplot(df_1,aes(x=pc50,y=Tsunami,colour=Tsunami))+ geom_point(size=2) + geom_errorbarh(aes(xmax = pc97.5, xmin =pc2.5),height=0.5)+theme_bw()+theme(legend.position='None',axis.title.y=element_text(angle=0,vjust=1,hjust=0))+ggtitle('Age of Tsunamis with 95% error bounds\n')+xlab('Age (thousands of years')+ scale_x_continuous(breaks=seq(2500,7600,by=500),limits=c(2500,7600))
> 
> ##########################################################################################
> 
> # An alternative version - plot densities but facet by Tsunami
> output_3 = c(output_2[,'theta[1]'],output_2[,'theta[2]'],output_2[,'theta[3]'],output_2[,'theta[4]'],output_2[,'theta[5]'],output_2[,'theta[6]'],output_2[,'theta[7]'],output_2[,'theta[8]'],output_2[,'theta[9]'],output_2[,'theta[11]'],output_2[,'theta[12]'],output_2[,'theta[14]'])
> Tsunami = rep(factor(paste('T',12:1,sep=''),levels=paste('T',12:1,sep='')),each=4804)
> df_2 = data.frame(Tsunami=Tsunami,Age=output_3)
Error in data.frame(Tsunami = Tsunami, Age = output_3) : 
  arguments imply differing number of rows: 57648, 96000
Execution halted
